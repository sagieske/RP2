% Chapter X

\chapter{Results} % Chapter title

\label{ch:results} % For referencing the chapter elsewhere, use \autoref{ch:name}

In this chapter the results of this research are described and a discussion on these results is given. %\autoref{sec:res_activity} shows the results of the activity classification. In \autoref{sec:res_extraction} the results of the two different activity extraction methods are described and finally, in \autoref{sec:res_ranking}, the results for ranking popular activities are shown.

\section{Extraction of JPEG quantization tables}
In total, there are 1,016 unique sets of JPEG quantization tables retrieved from the images. In \autoref{tab:dqt_count}, the number of unique JPEG quantization tables per camera model are shown. As can be derived from these numbers, there are distinct JPEG quantization tables that have been found for multiple camera models. There are 398 quantization tables found in images with different camera models. 

As the chrominance color space can be divided into chrominance-red and chrominance-blue, it could have occurred that 3 JPEG quantization tables are retrieved for an image. However, only sets of 2 JPEG quantization tables are found in the dataset.

\section{Feature Selection}
The two JPEG quantization tables are converted to a set of features and the extra statistical features (as described in \autoref{sec:featselect}) are added. Each JPEG quantization table contains 64 values to which 105 extra statistical features per table are added, which gives a total of 338 attributes per image. The extra features had no impact on the scores for the evaluation. Therefore, these extra statistical features are omitted from the feature set.

After the feature selection procedure, the identifiable parameters for the decision tree learning algorithm are reduced to 50 parameters. In \autoref{tab:important} the importance of every attribute is depicted. The parameters do not show a clear correlation with the tables. The total importance of the luminance JPEG quantization table is 0.56 and total importance of the chrominance JPEG quantization table is 0.44. 
This shows that both JPEG quantization tables have a comparable importance in this camera identification method.


\section{Decision Tree Learning}
The decision tree learning algorithm has created a decision tree of 603 nodes with a depth of 26 nodes. The average F$_2$-score is 89\% for the prediction of the camera make and 80\% for the prediction of the camera model. The exact F$_2$-scores for every camera make and model are described in \autoref{tab:fscore_everyclass_make} and \autoref{tab:fscore_everyclass_model}, respectively.

The decision tree model gains high scores for the prediction of the camera make. The mean of F$_2$-scores for the prediction of the camera make is 85.05\% with a standard deviation of 16.32\%. There are a few camera makes that have a significantly lower F$_2$-score, such as Motorola with an F$_2$-score of 43.30\%. This result is unexpected, because the dataset contains 4060 images made by Motorola cameras in which only 6 unique sets of JPEG quantization tables are found. The decision tree only needs to correctly classify a small number of sets (i.e. these 6 unique sets) in its tree for a high F$_2$-score. This result can be explained by the occurrence of these sets in images from other camera makes. If the set of tables is found more frequently for other camera makes, the decision tree will set the predicted label for these tables for the other camera make.
In contrast, the dataset contains 39 unique sets of JPEG quantization tables for 1318 images made by a Panasonic device, which is significantly higher, and this class has an F$_2$-score of 100\%.

The decision tree model also gains a satisfactory F$_2$-score for the prediction of the camera model. However, at closer inspection the F$_2$-scores for the classes show a big variance between the classes: the mean of the F$_2$-scores is 59.30\% with a standard deviation of 37.46\%. For example, the prediction for camera model Samsung NX1000 gains a F$_2$-score of 0\%. No image that is made with this camera model is correctly classified. There were 4 unique sets of JPEG quantization tables encountered for this camera model in 350 images. This result can also be explained by the occurrence of these tables in images from other camera models of which more examples were present in the dataset. In contrast, the Agfa Sensor505-x camera model gains a F$_2$-score of 96.29\% where the dataset contains 143 unique sets of JPEG quantization tables in 209 images from this camera model.

Because the decision tree model makes a unique map of a set of JPEG quantization tables to a single camera make or model, a trade-off can be found between the F$_2$-scores. When a set of JPEG quantization tables is encountered for two (or more) different classes, it maps the set to only one of these two (or more) classes. As a result the F$_2$-score will increase for the class that is mapped to this set and the F$_2$-score will decrease for the classes that are not mapped to this set. In the prediction of the camera make, the trade-off between different classes is not strongly visible. The conclusion can be drawn that the occurrence of the same set of JPEG quantization tables for different camera models is more often found in images with the same camera make.

Another conclusion that can be drawn is that the presence of sets of JPEG quantization tables in images from other camera makes and models will affect the performance of the decision tree. The number of unique sets of JPEG quantization tables found for a camera make or model does not directly relate to the F$_2$-score for the prediction model, however, it can increase the probability for a set to be found in images from different camera makes or models and consequently create a trade-off between classes.

%In the following subsections the results of the decision tree evaluation is discussed as well as the comparison against the hash database models.



%\subsection{Evaluation}

\section{Comparison against hash database}
The decision tree model is compared to the two hash database models that are explained in \autoref{sec:impl_hash}. They are compared for the prediction of the camera make as well as the prediction of the camera model. An overview of the scores is given in \autoref{tab:fscore_make} and \autoref{tab:fscore_model}.

The decision tree model has the highest F$_2$-score for the prediction of the camera make. For the prediction of the camera model, it scores 3\% lower on the F$_2$-score than the 1$\rightarrow N$ hash database model. Overall, the decision tree model scores better than the 1$\rightarrow$1 hash database model and comparable to the 1$\rightarrow N$ hash database model.

The 1$\rightarrow N$ hash database model scores high on recall for both predictions. This result is explained by the fact that the hash database model stores all possible camera make and models for each unique set of JPEG quantization tables. It returns all possibilities and will receive a high recall as a result of the probability that the correct camera make/model in the returned set is very high. However, it receives low precision rates for the predictions of the camera make as well for the prediction of the camera model. This is also a result of the method returning all possibilities as many false positives are returned.

The 1$\rightarrow$1 hash database model has the lowest F$_2$-scores. This is a result of overfitting of data. This method only returns the first camera make/model class where this set of JPEG quantization tables is seen. The tables are stored as a single hash and consequently it will not recognize a slightly modified set of JPEG quantization tables since this results in a completely different hash.

\begin{table}[h]
\begin{center}

\begin{tabular}{| c| c| c| c|}
\hline
\textbf{Algorithm} & \textbf{Precision} & \textbf{Recall} & \textbf{F$_2$-score}\\
\hline
Hash (1$\rightarrow$1) & 79 \% & 68 \% & 68 \%\\
Hash (1$\rightarrow N$) & 50 \% & 99 \% & 83 \%\\
Decision tree & 90 \% & 89 \% & 89 \% \\
\hline
\end{tabular}
\caption{Camera Make Identification}
\label{tab:fscore_make}
\end{center}

\end{table}

%1300 tables which have mutliple possibilities and thereby increasing the search space for fuurther research
\begin{table}[h]
\begin{center}
\begin{tabular}{| c| c| c| c|}
\hline
\textbf{Algorithm} & \textbf{Precision} & \textbf{Recall} & \textbf{F$_2$-score}\\
\hline
Hash (1$\rightarrow$1) & 54 \% & 39 \% & 37 \%\\
Hash (1$\rightarrow N$) & 50 \% & 98 \% & 83 \%\\
Decision tree & 78 \% & 82 \% & 80 \% \\
\hline
\end{tabular}
\caption{Camera Model Identification}
\label{tab:fscore_model}
\end{center}

\end{table}


\section{Discussion}

Since a decision tree uses a one-to-one mapping from JPEG quantization tables to a camera make/model, it will not perform perfectly on tables that occur at multiple camera make/models. The classifier makes a choice to which camera make/model this table is mapped. In contrast, the 
1$\rightarrow N$ hash database prediction model returns all possible camera makes/models. This method gains a high recall, but receives a low precision rate. Because all possibilities are returned, instead of only one camera make/model, the search space for these classes is significantly bigger than for decision tree learning. In order to decrease the search space for further processing with other camera identification methods, decision tree learning is preferred because it receives high scores for recall as well as precision.

Although the decision tree learning algorithm is prone to overfitting data, it will more accurately predict camera make and models for sets of JPEG quantization tables that differ slightly. The hash database models will not recognize the set and will return a random value in this implementation. The decision tree model, however, only uses a subset of the features found in the JPEG quantization tables and as a result can handle small differentiations better.

With respect to the creation of the prediction model, the hash database models are more easily trained. When a new set of JPEG quantization tables for a camera make/model occurs, it can be hashed and immediately stored in the database. In contrast, the decision tree model needs to be re-evaluated at the occurrence of a new set because this can result in a different decision tree.

It should be taken into account that the dataset only consists of original images. Image editing software such as Photoshop also use JPEG compression and will contain JPEG quantization tables correlated to Photoshop instead of their original camera make or model. For the decision tree learning algorithm, images that are edited with Photoshop will be predicted as belonging to the same source even though the original images are made with different camera makes and models. 
%----------------------------------------------------------------------------------------

